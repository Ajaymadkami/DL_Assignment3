{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11585380,"sourceType":"datasetVersion","datasetId":7264109}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\n# Special tokens for sequence processing\nSTART_TOKEN = '\\t'\nEND_TOKEN = '\\n'\nPAD_TOKEN = ' '\n\ndef load_dataset(file_path, as_characters=False):\n    \"\"\"\n    Loads data from a TSV file and returns input-output pairs.\n    If as_characters is True, returns lists of characters; otherwise, returns strings.\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as file:\n        lines = [line.strip().split('\\t') for line in file if line.strip()]\n    # Assuming the format: target \\t input\n    sources = [entry[1] for entry in lines]\n    targets = [entry[0] for entry in lines]\n    if as_characters:\n        sources = [list(text) for text in sources]\n        targets = [list(text) for text in targets]\n    return sources, targets\n\ndef vectorize_sequences(sequences, max_length, char_to_index):\n    \"\"\"\n    Converts sequences of characters to sequences of integer indices, padded to max_length.\n    \"\"\"\n    return np.array([\n        [char_to_index.get(char, char_to_index[PAD_TOKEN]) for char in seq] +\n        [char_to_index[PAD_TOKEN]] * (max_length - len(seq))\n        for seq in sequences\n    ])\n\ndef prepare_data(inputs, max_input_len, input_vocab, targets=None, max_output_len=None, output_vocab=None):\n    \"\"\"\n    Prepares encoder and decoder inputs and targets for training sequence models.\n    \"\"\"\n    encoder_input = vectorize_sequences(inputs, max_input_len, input_vocab)\n\n    decoder_input = None\n    decoder_target = None\n\n    if targets is not None and max_output_len is not None and output_vocab is not None:\n        # Add start and end tokens to targets\n        decoder_input = np.array([\n            [output_vocab[START_TOKEN]] +\n            [output_vocab[char] for char in seq] +\n            [output_vocab[END_TOKEN]] +\n            [output_vocab[PAD_TOKEN]] * (max_output_len - len(seq) - 2)\n            for seq in targets\n        ])\n        decoder_target = np.zeros((decoder_input.shape[0], max_output_len, len(output_vocab)), dtype='float32')\n        for i, seq in enumerate(decoder_input):\n            for t in range(1, len(seq)):\n                decoder_target[i, t-1, seq[t]] = 1.0\n            # Pad the rest with PAD_TOKEN\n            decoder_target[i, t:, output_vocab[PAD_TOKEN]] = 1.0\n\n    return encoder_input, decoder_input, decoder_target\n\ndef build_vocabularies(train_src, train_tgt, val_src, val_tgt):\n    \"\"\"\n    Builds character-level vocabularies for both input and output languages.\n    Returns encoding/decoding dictionaries and max sequence lengths.\n    \"\"\"\n    input_chars = set(char for seq in train_src + val_src for char in seq)\n    output_chars = set(char for seq in train_tgt + val_tgt for char in seq)\n\n    input_vocab = {char: idx for idx, char in enumerate(sorted(input_chars | {PAD_TOKEN}))}\n    input_vocab_dec = sorted(input_vocab, key=lambda k: input_vocab[k])\n    max_input_len = max(len(seq) for seq in train_src + val_src)\n\n    # Output vocab includes special tokens\n    output_vocab = {START_TOKEN: 0, END_TOKEN: 1}\n    idx = 2\n    for char in sorted(output_chars | {PAD_TOKEN}):\n        if char not in output_vocab:\n            output_vocab[char] = idx\n            idx += 1\n    output_vocab_dec = sorted(output_vocab, key=lambda k: output_vocab[k])\n    max_output_len = max(len(seq) for seq in train_tgt + val_tgt) + 2  # +2 for start/end tokens\n\n    print(f\"Training samples: {len(train_src)}\")\n    print(f\"Validation samples: {len(val_src)}\")\n    print(f\"Unique input tokens: {len(input_vocab)}\")\n    print(f\"Unique output tokens: {len(output_vocab)}\")\n    print(f\"Max input length: {max_input_len}\")\n    print(f\"Max output length: {max_output_len}\")\n\n    return input_vocab, input_vocab_dec, output_vocab, output_vocab_dec, max_input_len, max_output_len\n\n# File paths (update as needed)\ntrain_path = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'\nval_path = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv'\ntest_path = '/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv'\n\n# Load datasets\ntrain_inputs, train_targets = load_dataset(train_path)\nval_inputs, val_targets = load_dataset(val_path)\ntest_inputs, test_targets = load_dataset(test_path)\n\n# Build vocabularies and get sequence lengths\n(input_vocab, input_vocab_dec, output_vocab, output_vocab_dec,\n max_input_len, max_output_len) = build_vocabularies(train_inputs, train_targets, val_inputs, val_targets)\n\n# Prepare data for model input\ntrain_enc_in, train_dec_in, train_dec_out = prepare_data(\n    train_inputs, max_input_len, input_vocab, train_targets, max_output_len, output_vocab)\nval_enc_in, val_dec_in, val_dec_out = prepare_data(\n    val_inputs, max_input_len, input_vocab, val_targets, max_output_len, output_vocab)\ntest_enc_in, test_dec_in, test_dec_out = prepare_data(\n    test_inputs, max_input_len, input_vocab, test_targets, max_output_len, output_vocab)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:46:44.690111Z","iopub.execute_input":"2025-05-21T09:46:44.690609Z","iopub.status.idle":"2025-05-21T09:46:45.709668Z","shell.execute_reply.started":"2025-05-21T09:46:44.690584Z","shell.execute_reply":"2025-05-21T09:46:45.708896Z"}},"outputs":[{"name":"stdout","text":"Training samples: 44204\nValidation samples: 4358\nUnique input tokens: 27\nUnique output tokens: 66\nMax input length: 20\nMax output length: 21\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"print(input_vocab)\nprint(output_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:46:48.201196Z","iopub.execute_input":"2025-05-21T09:46:48.201775Z","iopub.status.idle":"2025-05-21T09:46:48.206040Z","shell.execute_reply.started":"2025-05-21T09:46:48.201750Z","shell.execute_reply":"2025-05-21T09:46:48.205280Z"}},"outputs":[{"name":"stdout","text":"{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n{'\\t': 0, '\\n': 1, ' ': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'व': 46, 'श': 47, 'ष': 48, 'स': 49, 'ह': 50, '़': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, 'ॐ': 65}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nimport random\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:46:57.150601Z","iopub.execute_input":"2025-05-21T09:46:57.150882Z","iopub.status.idle":"2025-05-21T09:47:01.126989Z","shell.execute_reply.started":"2025-05-21T09:46:57.150860Z","shell.execute_reply":"2025-05-21T09:47:01.126208Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n# Dataset class with device transfer\nclass TransliterationDataset(Dataset):\n    def __init__(self, enc_inputs, dec_inputs, dec_targets):\n        self.enc_inputs = torch.LongTensor(enc_inputs).to(device)\n        self.dec_inputs = torch.LongTensor(dec_inputs).to(device)\n        self.dec_targets = torch.FloatTensor(dec_targets).to(device)\n\n    def __len__(self):\n        return len(self.enc_inputs)\n\n    def __getitem__(self, idx):\n        return self.enc_inputs[idx], self.dec_inputs[idx], self.dec_targets[idx]\n\n# 2. Encoder\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, dropout, cell_type, bidirectional=False):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.cell_type = cell_type\n        self.bidirectional = bidirectional\n        \n        if cell_type == \"LSTM\":\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, \n                              dropout=dropout, bidirectional=bidirectional, batch_first=True)\n        elif cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers,\n                             dropout=dropout, bidirectional=bidirectional, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers,\n                             dropout=dropout, bidirectional=bidirectional, batch_first=True)\n\n    def forward(self, x):\n        embedded = self.embedding(x)\n        outputs, hidden = self.rnn(embedded)\n        return outputs, hidden\n\n# 3. Decoder\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embedding_size, hidden_size, num_layers, dropout, cell_type):\n        super().__init__()\n        self.embedding = nn.Embedding(output_size, embedding_size)\n        self.cell_type = cell_type\n        \n        if cell_type == \"LSTM\":\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, \n                              dropout=dropout, batch_first=True)\n        elif cell_type == 'RNN':\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers,\n                             dropout=dropout, batch_first=True)\n        elif cell_type == 'GRU':\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers,\n                             dropout=dropout, batch_first=True)\n            \n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden):\n        x = self.embedding(x)\n        output, hidden = self.rnn(x, hidden)\n        prediction = self.fc(output)\n        return prediction, hidden\n\n# 4. Seq2Seq Model\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, n_enc_layers, n_dec_layers, cell_type):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.cell_type = cell_type\n        self.n_enc_layers = n_enc_layers\n        self.n_dec_layers = n_dec_layers\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        batch_size = trg.shape[0]\n        trg_len = trg.shape[1]\n        trg_vocab_size = self.decoder.fc.out_features\n        \n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(device)\n        _, hidden = self.encoder(src)\n        \n        # Handle layer mismatch\n        if self.n_enc_layers != self.n_dec_layers:\n            if self.cell_type == 'LSTM':\n                hidden = (hidden[0][:self.n_dec_layers], hidden[1][:self.n_dec_layers])\n            else:\n                hidden = hidden[:self.n_dec_layers]\n        \n        input = trg[:, 0].unsqueeze(1)\n        \n        for t in range(1, trg_len):\n            output, hidden = self.decoder(input, hidden)\n            outputs[:, t] = output.squeeze(1)\n            \n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(2)\n            input = trg[:, t].unsqueeze(1) if teacher_force else top1\n            \n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:47:07.550019Z","iopub.execute_input":"2025-05-21T09:47:07.550874Z","iopub.status.idle":"2025-05-21T09:47:07.563256Z","shell.execute_reply.started":"2025-05-21T09:47:07.550847Z","shell.execute_reply":"2025-05-21T09:47:07.562588Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 5. Training/Evaluation Functions\ndef calculate_accuracy(preds, targets):\n    preds = preds.argmax(dim=2)\n    correct = (preds == targets).float()\n    mask = (targets != 0).float()\n    return (correct * mask).sum() / mask.sum()\n\ndef train(model, dataloader, optimizer, criterion):\n    model.train()\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    for enc_in, dec_in, dec_out in tqdm(dataloader, desc='Training'):\n        optimizer.zero_grad()\n        output = model(enc_in, dec_in)\n        loss = criterion(output[:,1:].reshape(-1, output.shape[-1]), \n                        dec_out[:,1:].reshape(-1, dec_out.shape[-1]))\n        loss.backward()\n        optimizer.step()\n        \n        acc = calculate_accuracy(output[:,1:], dec_in[:,1:])\n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n        \n    return epoch_loss/len(dataloader), epoch_acc/(2*len(dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:47:21.275715Z","iopub.execute_input":"2025-05-21T09:47:21.275955Z","iopub.status.idle":"2025-05-21T09:47:21.281976Z","shell.execute_reply.started":"2025-05-21T09:47:21.275939Z","shell.execute_reply":"2025-05-21T09:47:21.281241Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion):\n    model.eval()\n    epoch_loss = 0\n    epoch_acc = 0\n    \n    with torch.no_grad():\n        for enc_in, dec_in, dec_out in tqdm(dataloader, desc='Evaluating'):\n            output = model(enc_in, dec_in, teacher_forcing_ratio=0)\n            loss = criterion(output[:,1:].reshape(-1, output.shape[-1]), \n                            dec_out[:,1:].reshape(-1, dec_out.shape[-1]))\n            acc = calculate_accuracy(output[:,1:], dec_in[:,1:])\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n            \n    return epoch_loss/len(dataloader), epoch_acc/(2*len(dataloader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:47:30.233278Z","iopub.execute_input":"2025-05-21T09:47:30.233885Z","iopub.status.idle":"2025-05-21T09:47:30.239077Z","shell.execute_reply.started":"2025-05-21T09:47:30.233859Z","shell.execute_reply":"2025-05-21T09:47:30.238273Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# 6. Data Loaders\ntrain_dataset = TransliterationDataset(train_enc_in, train_dec_in, train_dec_out)\nval_dataset = TransliterationDataset(val_enc_in, val_dec_in, val_dec_out)\ntest_dataset = TransliterationDataset(test_enc_in, test_dec_in, test_dec_out)\n\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Reinitialize model with fixed architecture\nencoder = Encoder(len(input_vocab), 256, 256, 2, 0.2, 'RNN', bidirectional=True).to(device)\ndecoder = Decoder(len(output_vocab), 256, 256, 3, 0.2, 'RNN').to(device)\nmodel = Seq2Seq(encoder, decoder, 2, 3, 'RNN').to(device)\n\n# Restart training\noptimizer = optim.Adam(model.parameters())\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in range(1):\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)\n    \n    print(f'Epoch {epoch+1:02}')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:47:39.385543Z","iopub.execute_input":"2025-05-21T09:47:39.386070Z","iopub.status.idle":"2025-05-21T09:48:05.937331Z","shell.execute_reply.started":"2025-05-21T09:47:39.386046Z","shell.execute_reply":"2025-05-21T09:48:05.936608Z"}},"outputs":[{"name":"stderr","text":"Training: 100%|██████████| 691/691 [00:22<00:00, 30.32it/s]\nEvaluating: 100%|██████████| 69/69 [00:00<00:00, 74.00it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 01\n\tTrain Loss: 0.033 | Train Acc: 32.09%\n\t Val. Loss: 0.024 |  Val. Acc: 33.20%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# # Prediction function with proper device handling\n# def predict(model, input_seq, output_vocab, output_vocab_dec, max_output_len, device):\n#     model.eval()\n#     input_tensor = torch.LongTensor(input_seq).unsqueeze(0).to(device)\n    \n#     with torch.no_grad():\n#         _, hidden = model.encoder(input_tensor)\n        \n#         # Handle layer mismatch and bidirectional\n#         if model.n_enc_layers != model.n_dec_layers:\n#             if model.cell_type == 'LSTM':\n#                 hidden = (hidden[0][:model.n_dec_layers], hidden[1][:model.n_dec_layers])\n#             else:\n#                 hidden = hidden[:model.n_dec_layers]\n        \n#         decoder_input = torch.LongTensor([[output_vocab[START_TOKEN]]]).to(device)\n#         decoded_chars = []\n        \n#         for _ in range(max_output_len):\n#             output, hidden = model.decoder(decoder_input, hidden)\n#             topi = output.argmax(-1)\n#             predicted_idx = topi.item()\n            \n#             if predicted_idx == output_vocab[END_TOKEN]:\n#                 break\n                \n#             decoded_char = output_vocab_dec[predicted_idx]\n#             decoded_chars.append(decoded_char)\n#             decoder_input = torch.LongTensor([[predicted_idx]]).to(device)\n    \n#     return ''.join(decoded_chars)\n\n# # Generate predictions for first 100 test samples\n# num_samples = 4500\n# predictions = []\n\n# for i in tqdm(range(num_samples), desc=\"Generating Predictions\"):\n#     input_seq = test_enc_in[i]\n#     target_text = test_targets[i]\n#     predicted_text = predict(\n#         model, \n#         input_seq, \n#         output_vocab, \n#         output_vocab_dec, \n#         max_output_len, \n#         device\n#     )\n#     predictions.append((test_inputs[i], target_text, predicted_text))\n\n# # Display sample predictions\n# print(\"\\nSample Predictions:\")\n# for i in range(10):\n#     src, tgt, pred = predictions[i]\n#     print(f\"Input: {src}\")\n#     print(f\"Target: {tgt}\")\n#     print(f\"Predicted: {pred}\")\n#     print(\"-\" * 50)\n\n# # Calculate accuracy\n# correct = sum(1 for _, tgt, pred in predictions if pred == tgt)\n# print(f\"\\nAccuracy on {num_samples} samples: {correct/num_samples:.2%}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:48:07.997750Z","iopub.execute_input":"2025-05-21T09:48:07.998362Z","iopub.status.idle":"2025-05-21T09:48:08.002356Z","shell.execute_reply.started":"2025-05-21T09:48:07.998335Z","shell.execute_reply":"2025-05-21T09:48:08.001668Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import wandb\n\nwandb.login(key='43cc4a6022bf573f56ea92522b3e44bac7bd28b6')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:48:09.859809Z","iopub.execute_input":"2025-05-21T09:48:09.860479Z","iopub.status.idle":"2025-05-21T09:48:18.594561Z","shell.execute_reply.started":"2025-05-21T09:48:09.860454Z","shell.execute_reply":"2025-05-21T09:48:18.593695Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33majay-madkami-iitm\u001b[0m (\u001b[33majay-madkami-iitm-indian-institute-of-technology-mad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Define the sweep configuration\nsweep_config = {\n    'method': 'bayes',  # Random search\n    'metric': {\n        'name': 'accuracy',\n        'goal': 'maximize'  # Objective: Maximize accuracy\n    },\n    'parameters': {\n        'cell_type': {'values': ['RNN', 'GRU', 'LSTM']},\n        'n_enc_layers': {'values': [1, 2, 3]},\n        'n_dec_layers': {'values': [1, 2, 3]},\n        'hidden_layer_size': {'values': [16, 32, 64, 256]},\n        'emb_size': {'values': [16, 32, 64, 256]},\n        'bidirectional': {'values': [True,False]},\n        'dropout': {'values': [0.2, 0.3]},\n        'epochs': {'values': [3, 5]} \n    }\n}\n\n# Initialize a new wandb sweep\nsweep_id = wandb.sweep(sweep_config, project=\"Assignment 3\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:53:44.801425Z","iopub.execute_input":"2025-05-21T09:53:44.801730Z","iopub.status.idle":"2025-05-21T09:53:45.095468Z","shell.execute_reply.started":"2025-05-21T09:53:44.801708Z","shell.execute_reply":"2025-05-21T09:53:45.094850Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 50qxhud8\nSweep URL: https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import wandb\n\ndef main():\n    # Initialize W&B run\n    wandb.init()\n    hyperparams = wandb.config\n    \n    # Model parameters from sweep\n    encoder = Encoder(\n        input_size=len(input_vocab),\n        embedding_size=hyperparams.emb_size,\n        hidden_size=hyperparams.hidden_layer_size,\n        num_layers=hyperparams.n_enc_layers,\n        dropout=hyperparams.dropout,\n        cell_type=hyperparams.cell_type,\n        bidirectional=hyperparams.bidirectional\n    ).to(device)\n\n    decoder = Decoder(\n        output_size=len(output_vocab),\n        embedding_size=hyperparams.emb_size,\n        hidden_size=hyperparams.hidden_layer_size,\n        num_layers=hyperparams.n_dec_layers,\n        dropout=hyperparams.dropout,\n        cell_type=hyperparams.cell_type\n    ).to(device)\n\n    model = Seq2Seq(\n        encoder, \n        decoder,\n        n_enc_layers=hyperparams.n_enc_layers,\n        n_dec_layers=hyperparams.n_dec_layers,\n        cell_type=hyperparams.cell_type\n    ).to(device)\n\n    # Training setup\n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.BCEWithLogitsLoss()\n    \n    # Training loop\n    for epoch in range(hyperparams.epochs):\n        train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n        val_loss, val_acc = evaluate(model, val_loader, criterion)\n        # Log metrics\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_acc\": train_acc,\n            \"val_loss\": val_loss,\n            \"val_acc\": val_acc\n        })\n        \n        print(f'Epoch {epoch+1:02}')\n        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n        print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')\n    \n    # Test evaluation\n    test_loss, test_acc = evaluate(model, test_loader, criterion)\n    # wandb.log({\"test_loss\": test_loss, \"test_acc\": test_acc})\n    # print(f'\\nFinal Test Accuracy: {test_acc*100:.2f}%')\n\n# Run the sweep\nwandb.agent(sweep_id, function=main, count=2) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T09:55:29.115653Z","iopub.execute_input":"2025-05-21T09:55:29.115924Z","iopub.status.idle":"2025-05-21T09:58:40.086537Z","shell.execute_reply.started":"2025-05-21T09:55:29.115901Z","shell.execute_reply":"2025-05-21T09:58:40.086034Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yyogsgo7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \temb_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_095536-yyogsgo7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/yyogsgo7' target=\"_blank\">magic-sweep-2</a></strong> to <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/yyogsgo7' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/yyogsgo7</a>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 691/691 [00:21<00:00, 31.72it/s]\nEvaluating: 100%|██████████| 69/69 [00:00<00:00, 111.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01\n\tTrain Loss: 0.078 | Train Acc: 31.19%\n\t Val. Loss: 0.035 |  Val. Acc: 32.62%\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 691/691 [00:21<00:00, 31.99it/s]\nEvaluating: 100%|██████████| 69/69 [00:00<00:00, 113.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 02\n\tTrain Loss: 0.030 | Train Acc: 31.90%\n\t Val. Loss: 0.026 |  Val. Acc: 32.65%\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 691/691 [00:21<00:00, 31.81it/s]\nEvaluating: 100%|██████████| 69/69 [00:00<00:00, 107.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 03\n\tTrain Loss: 0.025 | Train Acc: 32.36%\n\t Val. Loss: 0.024 |  Val. Acc: 33.20%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 71/71 [00:00<00:00, 114.27it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_acc</td><td>▁▅█</td></tr><tr><td>train_loss</td><td>█▂▁</td></tr><tr><td>val_acc</td><td>▁▁█</td></tr><tr><td>val_loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train_acc</td><td>0.32357</td></tr><tr><td>train_loss</td><td>0.02465</td></tr><tr><td>val_acc</td><td>0.33204</td></tr><tr><td>val_loss</td><td>0.02412</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">magic-sweep-2</strong> at: <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/yyogsgo7' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/yyogsgo7</a><br> View project at: <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_095536-yyogsgo7/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4foondc0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \temb_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_dec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_enc_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250521_095656-4foondc0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/4foondc0' target=\"_blank\">prime-sweep-3</a></strong> to <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/sweeps/50qxhud8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/4foondc0' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/4foondc0</a>"},"metadata":{}},{"name":"stderr","text":"Training: 100%|██████████| 691/691 [00:31<00:00, 22.13it/s]\nEvaluating: 100%|██████████| 69/69 [00:00<00:00, 85.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 01\n\tTrain Loss: 0.029 | Train Acc: 32.61%\n\t Val. Loss: 0.020 |  Val. Acc: 34.43%\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 691/691 [00:30<00:00, 22.36it/s]\nEvaluating: 100%|██████████| 69/69 [00:00<00:00, 85.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 02\n\tTrain Loss: 0.020 | Train Acc: 33.42%\n\t Val. Loss: 0.019 |  Val. Acc: 34.09%\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 691/691 [00:31<00:00, 22.28it/s]\nEvaluating: 100%|██████████| 69/69 [00:00<00:00, 82.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 03\n\tTrain Loss: 0.019 | Train Acc: 33.73%\n\t Val. Loss: 0.018 |  Val. Acc: 34.41%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 71/71 [00:00<00:00, 84.64it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_acc</td><td>▁▆█</td></tr><tr><td>train_loss</td><td>█▂▁</td></tr><tr><td>val_acc</td><td>█▁█</td></tr><tr><td>val_loss</td><td>█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train_acc</td><td>0.33729</td></tr><tr><td>train_loss</td><td>0.01913</td></tr><tr><td>val_acc</td><td>0.34407</td></tr><tr><td>val_loss</td><td>0.01752</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">prime-sweep-3</strong> at: <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/4foondc0' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203/runs/4foondc0</a><br> View project at: <a href='https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203' target=\"_blank\">https://wandb.ai/ajay-madkami-iitm-indian-institute-of-technology-mad/Assignment%203</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250521_095656-4foondc0/logs</code>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}